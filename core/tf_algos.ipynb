{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('standardenv': conda)",
   "metadata": {
    "interpreter": {
     "hash": "96b3fd1559923f45a2a7d38e899d8d549575064782cdf1848d466cdc642efcd4"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Tensorflow 2.0 Algos\n",
    "\n",
    "The main goal here is to cover off on some core machine learning algos.  Apply each algo to a problem and dataset.\n",
    "\n",
    "## What Algos?\n",
    "\n",
    "The main ones right now for this notebook are \n",
    "\n",
    "* Linear Regression\n",
    "* Classification\n",
    "* Clustering\n",
    "* Hidden Markov Models\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Google Collab Tip\n",
    "\n",
    "If using Google Collab then run \n",
    "\n",
    "\"%tensorflow_version 2.x  # this line is not required unless you are in a notebook\" \n",
    "\n",
    "Restart runtime if a different version is selected.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Linear Regression\n",
    "\n",
    "Very basic form of machine learning used to predict numeric values.  With the magic of linear algebra this is super easy for computers to compute.\n",
    "\n",
    "Using the Titanic dataset and the documentation from <https://www.tensorflow.org/tutorials/estimator/linear>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "from IPython.display import clear_output\n",
    "from six.moves import urllib"
   ]
  },
  {
   "source": [
    "## Loading the Dataset\n",
    "\n",
    "This will be used to predict the survival rate of the passengers for gender, age, class, etc."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v2.feature_column as fc\n",
    "\n",
    "import tensorflow as tf  \n",
    "print(tf.version)  # make sure the version is 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load up the dataset\n",
    "dftrain = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/train.csv')\n",
    "dfeval = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/eval.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = dftrain.pop('survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_eval = dfeval.pop('survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore with pandas\n",
    "dftrain.describe()"
   ]
  },
  {
   "source": [
    "# Shape of the datasets\n",
    "dftrain.shape[0], dfeval.shape[0]"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram\n",
    "dftrain.age.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain.sex.value_counts().plot(kind=\"barh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain['class'].value_counts().plot(kind=\"barh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([dftrain, y_train], axis=1).groupby('sex').survived.mean().plot(kind='barh')"
   ]
  },
  {
   "source": [
    "## Linear Regression and Feature Engineering\n",
    "\n",
    "You need setup numeric and categorical columns differently for machine learning.  Categorical values need to converted into some type of integer encoding using the `tf.feature_column.categorical_column_with_vocabulary_list()`\n",
    "\n",
    "For numeric columns, using the same idea but with `tf.feature_column.numeric_column()`\n",
    "\n",
    "Read more here <https://www.tensorflow.org/api_docs/python/tf/feature_column>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather an array of the categorial columns\n",
    "CATEGORIAL_COLUMNS = ['sex', 'n_siblings_spouses', 'parch', 'class', 'deck', 'embark_town', 'alone']\n",
    "\n",
    "# the same for numeric\n",
    "NUMERIC_COLUMNS = ['age', 'fare']\n",
    "\n",
    "feature_columns = []\n",
    "for feature_name in CATEGORIAL_COLUMNS:\n",
    "    vocabulary = dftrain[feature_name].unique() # get all the unique values in the column\n",
    "    feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary_list=vocabulary))\n",
    "\n",
    "for feature_name in NUMERIC_COLUMNS:\n",
    "    feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float32))\n",
    "\n",
    "print(feature_columns)"
   ]
  },
  {
   "source": [
    "### Creating the TF dataset\n",
    "\n",
    "When using the TF model, the data we pass comes in as a `tf.data.Dataset` object.  Therefore, we have to convert the pandas df into that object.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_fn(data_df, label_df, num_epochs=10, shuffle=True, batch_size=32):\n",
    "    def input_function():\n",
    "        ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df)) # create the tf object with the data and the labels\n",
    "        if shuffle:\n",
    "            ds = ds.shuffle(1000) # random order\n",
    "        ds = ds.batch(batch_size).repeat(num_epochs) \n",
    "        return ds\n",
    "    return input_function\n",
    "\n",
    "train_input_fn = make_input_fn(dftrain, y_train)\n",
    "eval_input_fn = make_input_fn(dfeval, y_eval, num_epochs=1, shuffle=False)"
   ]
  },
  {
   "source": [
    "### Creating the linear regression model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_est = tf.estimator.LinearClassifier(feature_columns=feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_est.train(train_input_fn)\n",
    "result = linear_est.evaluate(eval_input_fn)\n",
    "\n",
    "clear_output()\n",
    "print(result)"
   ]
  },
  {
   "source": [
    "### Creating some predictions\n",
    "\n",
    "Use `.predict()`.  This method will return a list of dicts that store a prediction for eacch of the entries in the dataset. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dicts = list(linear_est.predict(eval_input_fn))\n",
    "probs = pd.Series([pred['probabilities'][1] for pred in pred_dicts])\n",
    "\n",
    "probs.plot(kind='hist', bins=20, title='predicted probabilities')"
   ]
  },
  {
   "source": [
    "## Classification\n",
    "\n",
    "Predict different labels of a dataset.  This uses the Iris dataset.\n",
    "\n",
    "Using <https://www.tensorflow.org/tutorials/estimator/premade>\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals"
   ]
  },
  {
   "source": [
    "### The Dataset\n",
    "\n",
    "There are 3 different classes:\n",
    "* Setosa\n",
    "* Versicolor\n",
    "* Virginica\n",
    "\n",
    "With 4 different columns for sepal/pedal with length/width"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns \n",
    "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\n",
    "SPECIES = ['Setosa', 'Versicolor', 'Virginica']\n",
    "# Lets define some constants to help us later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = tf.keras.utils.get_file(\n",
    "    \"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n",
    "test_path = tf.keras.utils.get_file(\n",
    "    \"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\n",
    "\n",
    "train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0) # use the column names from before\n",
    "test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pop off the column and use as the label\n",
    "train_y = train.pop(\"Species\")\n",
    "test_y = test.pop(\"Species\")"
   ]
  },
  {
   "source": [
    "### Input function\n",
    "\n",
    "Just like with the other regression model from above, you have to create an input function."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(features, labels, training=True, batch_size=256):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(1000).repeat()\n",
    "    return dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing some feature column magic\n",
    "\n",
    "feature_columns = []\n",
    "for key in train.keys():\n",
    "    feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
    "print(feature_columns)"
   ]
  },
  {
   "source": [
    "### Building the classifier model\n",
    "\n",
    "There are A LOT of differnt classifier models.  Here are the two easiest ones:\n",
    "* `DNNClassifier`\n",
    "* `LinearClassifier`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the dnn with 2 hidden layers with 30 and 10 hidden nodes each\n",
    "# the hidden number is picked arbitrattly\n",
    "\n",
    "classifer = tf.estimator.DNNClassifier(\n",
    "    feature_columns=feature_columns,\n",
    "    hidden_units=[30,10],\n",
    "    n_classes=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Using Lambda as the input function\n",
    "\n",
    "classifer.train(\n",
    "    input_fn=lambda: input_fn(train, train_y, training=True),\n",
    "    steps=5000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### the model is bad... But lets evaluate the model!\n",
    "\n",
    "eval_result = classifer.evaluate(\n",
    "    input_fn=lambda: input_fn(test,test_y, training=False)\n",
    ")\n",
    "print('\\nTest set accuracy : {accuracy:0.3f}\\n'.format(**eval_result))"
   ]
  },
  {
   "source": [
    "## Hidden Markov Model\n",
    "\n",
    "\"The Hidden Markov Model is a finite set of states, each of which is associated with a (generally multidimensional) probability distribution []. Transitions among the states are governed by a set of probabilities called transition probabilities.\" (http://jedlik.phy.bme.hu/~gerjanos/HMM/node4.html)\n",
    "\n",
    "Using TF to work with probabilities to predict future events or states.  \n",
    "\n",
    "We're gonna predict the weather!\n",
    "<https://www.tensorflow.org/probability/api_docs/python/tfp/distributions/HiddenMarkovModel>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_probability as tfp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfd = tfp.distributions\n",
    "\n",
    "# Creating a simple weather model\n",
    "\n",
    "# Represents a cold day with 0 and a hot day with 1\n",
    "# The first day of a sequence has a 0.8 chance of being cold.\n",
    "# The model using categorical distribution:\n",
    "\n",
    "initial_distribution = tfd.Categorical(probs=[0.8,0.2])\n",
    "\n",
    "# A cold day has a 30% chance of being followed by a hot day\n",
    "# and a hot day has a 20% chance of being followed by a cold day\n",
    "# This is the simple model of that statement\n",
    "\n",
    "transition_distribution = tfd.Categorical(probs=[[0.7, 0.3],\n",
    "                                                [0.2, 0.8]])\n",
    "\n",
    "# Additionally that on each day the temperature is normally distributed with \n",
    "# a mean and std dev 0 / 5 on a cold day and mean and std dev 15 / 10 on a hot day\n",
    "# Modeled like\n",
    "\n",
    "observation_distribution = tfd.Normal(loc=[0.,15.], scale=[5.,10.])\n",
    "\n",
    "# These distributions into a single week long model \n",
    "\n",
    "model = tfd.HiddenMarkovModel(\n",
    "    initial_distribution=initial_distribution,\n",
    "    transition_distribution=transition_distribution,\n",
    "    observation_distribution=observation_distribution,\n",
    "    num_steps=7\n",
    ")\n",
    "\n",
    "model.mean()\n",
    "\n",
    "# model.log_prob(tf.zeros(shape=[7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}