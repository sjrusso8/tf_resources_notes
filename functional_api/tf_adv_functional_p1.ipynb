{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('standardenv': conda)",
   "metadata": {
    "interpreter": {
     "hash": "96b3fd1559923f45a2a7d38e899d8d549575064782cdf1848d466cdc642efcd4"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# More Advanced Functional Models\n",
    "\n",
    "Using the site <https://www.tensorflow.org/guide/keras/functional?hl=en> as a guide to practice coding up more complex models."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Using a single graph of layers to make multiple models\n",
    "\n",
    "Using the same stack of layers to instantiate two models: an `encoder` and an end-to-end `autoencoder` model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating th model layers\n",
    "\n",
    "encoder_input = tf.keras.Input(shape=(28,28,1), name=\"img_input\")\n",
    "\n",
    "# Creating various layers\n",
    "x = tf.keras.layers.Conv2D(16,3, activation=\"relu\")(encoder_input)\n",
    "x = tf.keras.layers.Conv2D(32,3, activation=\"relu\")(x)\n",
    "x = tf.keras.layers.MaxPool2D(3)(x)\n",
    "x = tf.keras.layers.Conv2D(32,3, activation=\"relu\")(x)\n",
    "x = tf.keras.layers.Conv2D(16,3, activation=\"relu\")(x)\n",
    "encoder_output =  tf.keras.layers.GlobalMaxPool2D()(x)\n",
    "\n",
    "# Create the first model for encoder\n",
    "encoder = tf.keras.Model(encoder_input, encoder_output, name=\"encoder\")\n",
    "\n",
    "# Using the encoder model output for the next layer\n",
    "x = tf.keras.layers.Reshape((4,4,1))(encoder_output)\n",
    "x = tf.keras.layers.Conv2DTranspose(16,3,activation=\"relu\")(x) \n",
    "x = tf.keras.layers.Conv2DTranspose(32,3,activation=\"relu\")(x) \n",
    "x = tf.keras.layers.UpSampling2D(3)(x) \n",
    "x = tf.keras.layers.Conv2DTranspose(16,3,activation=\"relu\")(x)\n",
    "decoder_output = tf.keras.layers.Conv2DTranspose(1,3,activation=\"relu\")(x)\n",
    "\n",
    "# Define the second model\n",
    "auto_encoder = tf.keras.Model(encoder_input, decoder_output,name=\"auto_encoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"encoder\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nimg_input (InputLayer)       [(None, 28, 28, 1)]       0         \n_________________________________________________________________\nconv2d_8 (Conv2D)            (None, 26, 26, 16)        160       \n_________________________________________________________________\nconv2d_9 (Conv2D)            (None, 24, 24, 32)        4640      \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 8, 8, 32)          0         \n_________________________________________________________________\nconv2d_10 (Conv2D)           (None, 6, 6, 32)          9248      \n_________________________________________________________________\nconv2d_11 (Conv2D)           (None, 4, 4, 16)          4624      \n_________________________________________________________________\nglobal_max_pooling2d_2 (Glob (None, 16)                0         \n=================================================================\nTotal params: 18,672\nTrainable params: 18,672\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"auto_encoder\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nimg_input (InputLayer)       [(None, 28, 28, 1)]       0         \n_________________________________________________________________\nconv2d_8 (Conv2D)            (None, 26, 26, 16)        160       \n_________________________________________________________________\nconv2d_9 (Conv2D)            (None, 24, 24, 32)        4640      \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 8, 8, 32)          0         \n_________________________________________________________________\nconv2d_10 (Conv2D)           (None, 6, 6, 32)          9248      \n_________________________________________________________________\nconv2d_11 (Conv2D)           (None, 4, 4, 16)          4624      \n_________________________________________________________________\nglobal_max_pooling2d_2 (Glob (None, 16)                0         \n_________________________________________________________________\nreshape_2 (Reshape)          (None, 4, 4, 1)           0         \n_________________________________________________________________\nconv2d_transpose_4 (Conv2DTr (None, 6, 6, 16)          160       \n_________________________________________________________________\nconv2d_transpose_5 (Conv2DTr (None, 8, 8, 32)          4640      \n_________________________________________________________________\nup_sampling2d_1 (UpSampling2 (None, 24, 24, 32)        0         \n_________________________________________________________________\nconv2d_transpose_6 (Conv2DTr (None, 26, 26, 16)        4624      \n_________________________________________________________________\nconv2d_transpose_7 (Conv2DTr (None, 28, 28, 1)         145       \n=================================================================\nTotal params: 28,241\nTrainable params: 28,241\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "auto_encoder.summary()"
   ]
  },
  {
   "source": [
    "### Notes for above\n",
    "\n",
    "The reverse of a `Conv2D` layers is `Conv2DTranspose` layer, and the reverse of a `MaxPooling2D` layer is an `UpSampling2D` layers"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Chaining Different Models together\n",
    "\n",
    "Using the same structure as above, but creating an `encoder`, a `decoder`, and chain them to obtain the `autoencoder` model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"encoder\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nimg_input (InputLayer)       [(None, 28, 28, 1)]       0         \n_________________________________________________________________\nconv2d_12 (Conv2D)           (None, 26, 26, 16)        160       \n_________________________________________________________________\nconv2d_13 (Conv2D)           (None, 24, 24, 32)        4640      \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 8, 8, 32)          0         \n_________________________________________________________________\nconv2d_14 (Conv2D)           (None, 6, 6, 32)          9248      \n_________________________________________________________________\nconv2d_15 (Conv2D)           (None, 4, 4, 16)          4624      \n_________________________________________________________________\nglobal_max_pooling2d_3 (Glob (None, 16)                0         \n=================================================================\nTotal params: 18,672\nTrainable params: 18,672\nNon-trainable params: 0\n_________________________________________________________________\nModel: \"decoder\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nencoded_img (InputLayer)     [(None, 16)]              0         \n_________________________________________________________________\nreshape_3 (Reshape)          (None, 4, 4, 1)           0         \n_________________________________________________________________\nconv2d_transpose_8 (Conv2DTr (None, 6, 6, 16)          160       \n_________________________________________________________________\nconv2d_transpose_9 (Conv2DTr (None, 8, 8, 32)          4640      \n_________________________________________________________________\nup_sampling2d_2 (UpSampling2 (None, 24, 24, 32)        0         \n_________________________________________________________________\nconv2d_transpose_10 (Conv2DT (None, 26, 26, 16)        4624      \n_________________________________________________________________\nconv2d_transpose_11 (Conv2DT (None, 28, 28, 1)         145       \n=================================================================\nTotal params: 9,569\nTrainable params: 9,569\nNon-trainable params: 0\n_________________________________________________________________\nModel: \"autoencoder\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nimg_autoencoder (InputLayer) [(None, 28, 28, 1)]       0         \n_________________________________________________________________\nencoder (Functional)         (None, 16)                18672     \n_________________________________________________________________\ndecoder (Functional)         (None, 28, 28, 1)         9569      \n=================================================================\nTotal params: 28,241\nTrainable params: 28,241\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Creating the same model layers as above\n",
    "\n",
    "encoder_input = tf.keras.Input(shape=(28,28,1), name=\"img_input\")\n",
    "\n",
    "# Creating various layers\n",
    "x = tf.keras.layers.Conv2D(16,3, activation=\"relu\")(encoder_input)\n",
    "x = tf.keras.layers.Conv2D(32,3, activation=\"relu\")(x)\n",
    "x = tf.keras.layers.MaxPool2D(3)(x)\n",
    "x = tf.keras.layers.Conv2D(32,3, activation=\"relu\")(x)\n",
    "x = tf.keras.layers.Conv2D(16,3, activation=\"relu\")(x)\n",
    "encoder_output =  tf.keras.layers.GlobalMaxPool2D()(x)\n",
    "\n",
    "# Create the first model for encoder\n",
    "encoder = tf.keras.Model(encoder_input, encoder_output, name=\"encoder\")\n",
    "encoder.summary()\n",
    "\n",
    "# Using the encoder model output for the next layer\n",
    "# This is the change\n",
    "decoder_input = tf.keras.Input(shape=(16,), name=\"encoded_img\")\n",
    "x = tf.keras.layers.Reshape((4,4,1))(decoder_input) # Change here as well\n",
    "x = tf.keras.layers.Conv2DTranspose(16,3,activation=\"relu\")(x) \n",
    "x = tf.keras.layers.Conv2DTranspose(32,3,activation=\"relu\")(x) \n",
    "x = tf.keras.layers.UpSampling2D(3)(x) \n",
    "x = tf.keras.layers.Conv2DTranspose(16,3,activation=\"relu\")(x)\n",
    "decoder_output = tf.keras.layers.Conv2DTranspose(1,3,activation=\"relu\")(x)\n",
    "\n",
    "# Define a seperate decoder model\n",
    "decoder = tf.keras.Model(decoder_input, decoder_output,name=\"decoder\")\n",
    "decoder.summary()\n",
    "\n",
    "auto_encoder_input = tf.keras.Input(shape=(28,28,1), name=\"img_autoencoder\")\n",
    "encoded_img = encoder(auto_encoder_input)\n",
    "decoded_img = decoder(encoded_img)\n",
    "auto_encoder = tf.keras.Model(auto_encoder_input, decoded_img, name=\"autoencoder\")\n",
    "auto_encoder.summary()"
   ]
  },
  {
   "source": [
    "### Notes from above\n",
    "\n",
    "The main point for the summary is to note that the `autoencoder` contains the sub-models for the `encoder` and `decoder`.  The summary does not show all of the sub-models but rather references them by name.  \n",
    "\n",
    "#### IMP!  The shapes\n",
    "\n",
    "You will notice that the shapes for the `encoder` input is (none, 28,28,1) and the `encoder` output is (none, 16).  This lines up with the inputs for each of the models in the summary\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Why do all of this?\n",
    "\n",
    "This leads into *ensembled* models."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"functional_13\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_8 (InputLayer)            [(None, 128)]        0                                            \n__________________________________________________________________________________________________\nfunctional_7 (Functional)       (None, 1)            129         input_8[0][0]                    \n__________________________________________________________________________________________________\nfunctional_9 (Functional)       (None, 1)            129         input_8[0][0]                    \n__________________________________________________________________________________________________\nfunctional_11 (Functional)      (None, 1)            129         input_8[0][0]                    \n__________________________________________________________________________________________________\naverage_1 (Average)             (None, 1)            0           functional_7[0][0]               \n                                                                 functional_9[0][0]               \n                                                                 functional_11[0][0]              \n==================================================================================================\nTotal params: 387\nTrainable params: 387\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    inputs = tf.keras.Input(shape=(128,))\n",
    "    outputs = tf.keras.layers.Dense(1)(inputs)\n",
    "    return tf.keras.Model(inputs, outputs)\n",
    "\n",
    "model1 = get_model()\n",
    "model2 = get_model()\n",
    "model3 = get_model()\n",
    "\n",
    "inputs = tf.keras.Input(shape=(128,))\n",
    "y1 = model1(inputs)\n",
    "y2 = model2(inputs)\n",
    "y3 = model3(inputs)\n",
    "outputs = tf.keras.layers.average([y1,y2,y3])\n",
    "ensemble_model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "ensemble_model.summary()"
   ]
  }
 ]
}